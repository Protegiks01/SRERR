### Title
Non-Deterministic DKG Blame Causes Vote Splitting and Validator Set Formation Failure

### Summary
The `blame_vartime()` function's binary search depends on the iteration order of statements in the batch verifier. During DKG share verification, shares are queued from a HashMap with non-deterministic iteration order across different validator processes, causing different validators to blame different participants when multiple shares are invalid. This vote splitting can prevent any participant from reaching the removal threshold, indefinitely stalling DKG and blocking validator set formation.

### Finding Description

**Exact Location:** [1](#0-0) 

The `blame_vartime()` function performs a binary search to identify one faulty statement. The function comment explicitly states it "will only return the ID of one invalid statement, even if multiple are invalid." [2](#0-1) 

In the DKG share verification flow, the `calculate_share()` function iterates over shares using `shares.drain()` on a HashMap. This iteration order is non-deterministic across different processes due to Rust's randomized hasher (SipHash with per-process random seed). Each share is queued into the BatchVerifier in this non-deterministic order, then `verify_with_vartime_blame()` is called, which uses the order-dependent binary search.

**Root Cause:**
Rust's HashMap uses a randomized hasher that generates a different seed for each process. When validators (running in separate processes) iterate over the same logical set of shares, they get different iteration orders. If multiple shares are invalid, the binary search in `blame_vartime()` will identify different participants as faulty depending on the order in which statements were queued.

**Why Existing Mitigations Fail:** [3](#0-2) 

While the system has `AdditionalBlameMachine::blame()` that deterministically re-verifies accusations, this only helps AFTER blame is reported. The initial non-deterministic blame reporting causes validators to publish `Transaction::RemoveParticipantDueToDkg` for different participants. [4](#0-3) 

The removal mechanism accumulates votes per participant. When votes split across multiple faulty participants, none may reach the threshold `t` required for removal, causing DKG to stall.

### Impact Explanation

**Specific Harm:**
- Validator set cannot complete DKG and form the threshold multisig
- Cross-chain operations (deposits, withdrawals, swaps) are blocked indefinitely
- The entire Serai network stalls for the affected validator set

**Quantified Impact:**
With n validators and threshold t = ⌈2n/3⌉ + 1, if k malicious/faulty participants each send invalid shares to different subsets of validators:
- Each honest validator reports one of the k faulty participants based on their HashMap iteration order
- If votes split roughly evenly, each faulty participant receives approximately n/k votes
- For k ≥ 3 and typical validator set sizes (n=7 with t=5, or n=10 with t=7), none reach threshold
- DKG remains stuck across reattempts since HashMap seeds persist per process

**Severity Justification:**
High severity - This directly violates Critical Invariant #2 (DKG integrity) and prevents validator set formation, which is required for all cross-chain operations. While it requires multiple faulty participants, it represents a fundamental consensus bug in the DKG protocol.

### Likelihood Explanation

**Required Conditions:**
1. Multiple participants (≥2) send invalid shares during DKG
2. Different validators receive different subsets of these invalid shares OR the same validator receives multiple invalid shares
3. HashMap iteration orders differ across validators (guaranteed in Rust)
4. Vote split prevents any participant from reaching threshold t

**Attack Complexity:**
Low - An attacker controlling 2-3 validator nodes can send invalid shares, triggering the vulnerability. No sophisticated cryptographic attacks required.

**Economic Feasibility:**
Moderate - Requires controlling multiple validator slots or coordinating with buggy/malicious validators. However, the impact (blocking the entire validator set) provides strong denial-of-service motivation.

**Detection Risk:**
High - The stalled DKG would be immediately visible, but determining the root cause (HashMap non-determinism) would be difficult without detailed analysis.

### Recommendation

**Primary Fix:**
Replace HashMap with BTreeMap or use deterministic iteration order in the DKG share verification flow: [5](#0-4) 

Change the `shares` parameter type from `HashMap<Participant, EncryptedMessage<...>>` to `BTreeMap<Participant, EncryptedMessage<...>>`, or explicitly sort participants before queuing:

```rust
// Sort participants to ensure deterministic ordering
let mut sorted_participants: Vec<_> = shares.keys().copied().collect();
sorted_participants.sort();

for l in sorted_participants {
  let share_bytes = shares.remove(&l).unwrap();
  // ... rest of processing
}
```

**Alternative Mitigation:**
Modify `blame_vartime()` to return ALL invalid statements rather than just one, ensuring complete detection: [6](#0-5) 

This would require additional cryptographic work but ensures all faulty participants are identified regardless of ordering.

**Testing Recommendations:**
1. Add test case with multiple invalid shares and verify consistent blame across multiple runs
2. Test with HashMap iteration in different orders (can be simulated with different seeds)
3. Verify DKG completes successfully when multiple participants are faulty

### Proof of Concept

**Exploitation Steps:**

1. Setup: 7 validators (V1-V7), threshold t=5, 3 malicious validators (M1, M2, M3)

2. M1, M2, M3 each generate invalid shares:
   - M1 sends invalid share to V1, V2
   - M2 sends invalid share to V3, V4  
   - M3 sends invalid share to V5, V6

3. Due to HashMap randomization:
   - V1's process has HashMap seed S1, iteration order: [M1, M2, M3, ...]
   - V2's process has HashMap seed S2, iteration order: [M2, M1, M3, ...]
   - V3's process has HashMap seed S3, iteration order: [M2, M3, M1, ...]
   - ... (different orders for each validator process)

4. Binary search in `blame_vartime()`:
   - V1 blames M1 (found first in its ordering)
   - V2 blames M2 (found first in its ordering)
   - V3 blames M2 (found first in its ordering)
   - V4 blames M1 (found first in its ordering)
   - V5 blames M3 (found first in its ordering)
   - V6 blames M3 (found first in its ordering)
   - V7 receives all valid shares

5. Vote accumulation:
   - M1: 2 votes (V1, V4) - below threshold t=5
   - M2: 2 votes (V2, V3) - below threshold t=5
   - M3: 2 votes (V5, V6) - below threshold t=5

6. Result: No participant removed, DKG stalls indefinitely across reattempts

**Expected vs Actual Behavior:**
- Expected: All faulty participants identified and removed, DKG proceeds
- Actual: Votes split, no participant reaches threshold, DKG permanently stalled

### Citations

**File:** crypto/multiexp/src/batch.rs (L103-123)
```rust
  /// Perform a binary search to identify which statement does not equal 0, returning None if all
  /// statements do.
  ///
  /// This function will only return the ID of one invalid statement, even if multiple are invalid.
  // A constant time variant may be beneficial for robust protocols
  pub fn blame_vartime(&self) -> Option<Id> {
    let mut slice = self.0.as_slice();
    while slice.len() > 1 {
      let split = slice.len() / 2;
      if multiexp_vartime(&flat(&slice[.. split])).is_identity().into() {
        slice = &slice[split ..];
      } else {
        slice = &slice[.. split];
      }
    }

    slice
      .first()
      .filter(|(_, value)| !bool::from(multiexp_vartime(value).is_identity()))
      .map(|(id, _)| *id)
  }
```

**File:** crypto/dkg/pedpop/src/lib.rs (L466-493)
```rust
    mut shares: HashMap<Participant, EncryptedMessage<C, SecretShare<C::F>>>,
  ) -> Result<BlameMachine<C>, PedPoPError<C>> {
    validate_map(
      &shares,
      &self.params.all_participant_indexes().collect::<Vec<_>>(),
      self.params.i(),
    )?;

    let mut batch = BatchVerifier::new(shares.len());
    let mut blames = HashMap::new();
    for (l, share_bytes) in shares.drain() {
      let (mut share_bytes, blame) =
        self.encryption.decrypt(rng, &mut batch, BatchId::Decryption(l), l, share_bytes);
      let share =
        Zeroizing::new(Option::<C::F>::from(C::F::from_repr(share_bytes.0)).ok_or_else(|| {
          PedPoPError::InvalidShare { participant: l, blame: Some(blame.clone()) }
        })?);
      share_bytes.zeroize();
      *self.secret += share.deref();

      blames.insert(l, blame);
      batch.queue(
        rng,
        BatchId::Share(l),
        share_verification_statements::<C>(self.params.i(), &self.commitments[&l], share),
      );
    }
    batch.verify_with_vartime_blame().map_err(|id| {
```

**File:** processor/src/key_gen.rs (L543-556)
```rust
        let substrate_blame = AdditionalBlameMachine::new(
          context(&id, SUBSTRATE_KEY_CONTEXT),
          params.n(),
          substrate_commitment_msgs,
        )
        .unwrap()
        .blame(accuser, accused, substrate_share, substrate_blame);
        let network_blame = AdditionalBlameMachine::new(
          context(&id, NETWORK_KEY_CONTEXT),
          params.n(),
          network_commitment_msgs,
        )
        .unwrap()
        .blame(accuser, accused, network_share, network_blame);
```

**File:** coordinator/src/tributary/handle.rs (L276-283)
```rust
        let prior_votes = VotesToRemove::get(self.txn, genesis, participant).unwrap_or(0);
        let signer_votes =
          self.spec.i(&[], signed.signer).expect("signer wasn't a validator for this network?");
        let new_votes = prior_votes + u16::from(signer_votes.end) - u16::from(signer_votes.start);
        VotesToRemove::set(self.txn, genesis, participant, &new_votes);
        if ((prior_votes + 1) ..= new_votes).contains(&self.spec.t()) {
          self.fatal_slash(participant, "RemoveParticipantDueToDkg vote")
        }
```
